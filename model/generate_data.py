import json
import random
import requests
from tqdm import tqdm
from bs4 import BeautifulSoup

places_data = {"places": []}

names = [
    "Café do Bairro",
    "Bella Café",
    "Café Aconchego",
    "Café Charmoso",
    "Café da Esquina",
    "Café das Artes",
    "Café com Carinho",
    "Café com Prosa",
    "Café dos Amigos",
    "Café do Dia",
    "Café e Cia",
    "Café Especial",
    "Café Expresso",
    "Café Saboroso",
    "Café Saudade",
    "Café Simpatia",
    "Café Sonhador",
    "Café Tentador",
    "Café Viver",
    "Café do Brasil",
    "Museu de Arte",
    "Parque Central",
    "Biblioteca Nacional",
    "Jardim Botânico",
    "Aquário",
    "Museu de História Natural",
    "Galeria de Arte",
    "Centro de Ciências",
    "Zoológico",
    "Parque de Diversões",
    "Teatro Municipal",
    "Monumento Histórico",
    "Museu de Ciência",
    "Centro Cultural",
    "Igreja Histórica",
    "Praça Central",
    "Mirante",
    "Catedral",
    "Estádio de Futebol",
    "Mercado Municipal",
    "Centro Esportivo",
    "Casa de Cultura",
    "Espaço de Eventos",
    "Fortaleza",
    "Palácio de Governo",
    "Estação Ferroviária",
    "Museu do Automóvel",
    "Parque Aquático",
    "Jardim Zoológico",
    "Planetário",
    "Museu do Índio",
    "Museu do Imigrante",
    "Observatório",
    "Museu do Trem",
    "Museu Naval",
    "Museu do Café",
    "Museu do Homem do Nordeste",
    "Museu de Antropologia",
    "Museu de Geologia",
    "Museu de História",
    "Museu de Paleontologia",
    "Museu da Vida",
    "Museu da República",
    "Museu do Mar",
    "Museu Ferroviário",
    "Museu Histórico e Artístico",
    "Museu de Ciências e Tecnologia",
    "Museu de Arte Sacra",
    "Museu da Memória",
    "Museu da Revolução",
    "Museu de Zoologia",
    "Museu do Folclore",
    "Museu do Boi",
    "Museu do Carro",
    "Museu da Aviação",
    "Museu do Futebol Brasileiro",
    "Museu do Patrimônio Histórico",
    "Museu do Patrimônio Cultural",
    "Museu da Herança",
    "Shopping Westfield",
    "Shopping of America",
    "Shopping The Dubai",
    "Shopping West Edmonton",
    "Shopping of the Emirates",
    "Shopping Paragon",
    "Shopping SM of Asia",
    "Berjaya Times Shopping Square",
    "Shopping CentralWorld",
    "The Shopping Galleria",
    "Chadstone Shopping Shopping Centre",
    "Tokyo Shopping Midtown",
    "Grand Shopping Indonesia",
    "ABC Shopping Achrafieh",
    "King of Shopping Prussia",
    "South Coast Shopping Plaza",
    "Shopping Malha",
    "Canal Walk Shopping Shopping Centre",
    "Shopping VivoCity",
    "Westfield Stratford Shopping City",
    "Festa das Cores",
    "Festa da Alegria",
    "Festa Tropical",
    "Festa no Céu",
    "Festa do Luau",
    "Festa dos Sonhos",
    "Festa da Fantasia",
    "Festa do Pijama",
    "Festa da Amizade",
    "Festa do Brilho",
    "Festa das Estrelas",
    "Festa das Flores",
    "Festa do Sorriso",
    "Festa da Música",
    "Festa da Dança",
    "Festa da Lua Cheia",
    "Festa da Primavera",
    "Festa do Verão",
    "Festa do Carnaval",
    "Festa do Ano Novo",
    "Rock Palace",
    "Hard Rock Cafe",
    "Rock'n'Roll Bar",
    "The Rolling Stone",
    "Guitar Street",
    "Rock Arena",
    "Rock Star Lounge",
    "Metalhead Tavern",
    "Electric Avenue Pub",
    "Grungy Dive Bar",
    "Punk Pit",
    "Heavy Metal Hangout",
    "Rockabilly Joint",
    "The Blues Basement",
    "Psychedelic Saloon",
    "Jam Session Joint",
    "Riff Raff's",
    "The Roaring Guitar",
    "Screaming Stage",
    "Headbanger Haven",
]

locations = [
    "São Paulo",
    "Rio de Janeiro",
    "Belo Horizonte",
    "Brasília",
    "Salvador",
    "Fortaleza",
    "Curitiba",
    "Manaus",
    "Recife",
    "Belém",
    "Porto Alegre",
    "Goiânia",
    "Guarulhos",
    "Campinas",
    "São Luís",
    "São Gonçalo",
    "Maceió",
    "Duque de Caxias",
    "Natal",
    "Campo Grande",
    "Teresina",
    "São Bernardo do Campo",
    "Nova Iguaçu",
    "João Pessoa",
    "Santo André",
    "Osasco",
    "Jaboatão dos Guararapes",
    "Ribeirão Preto",
    "Uberlândia",
    "Contagem",
    "Sorocaba",
    "Aracaju",
    "Feira de Santana",
    "Cuiabá",
    "Joinville",
    "Aparecida de Goiânia",
    "Londrina",
    "Ananindeua",
    "Niterói",
    "Porto Velho",
    "Campos dos Goytacazes",
    "Mauá",
    "São José dos Campos",
    "Santos",
    "Diadema",
    "Mogi das Cruzes",
    "Betim",
    "Jundiaí",
    "Caxias do Sul",
    "Florianópolis",
    "Macapá",
    "Canoas",
    "Bauru",
    "Vitória",
    "São Vicente",
    "Pelotas",
    "Franca",
    "Blumenau",
    "Ponta Grossa",
    "Petrolina",
    "Campina Grande",
    "Boa Vista",
    "Piracicaba",
    "Montes Claros",
    "Rio Branco",
    "Santarém",
    "Cascavel",
    "Hortolândia",
    "Rondonópolis",
    "Palmas",
    "Várzea Grande",
    "Marabá",
    "Itaquaquecetuba",
    "Maringá",
    "Anápolis",
    "Barueri",
    "Vila Velha",
    "Volta Redonda",
    "Santa Maria",
    "Suzano",
    "Sete Lagoas",
    "Divinópolis",
    "Caruaru",
    "Ibirité",
    "Criciúma",
    "São José do Rio Preto",
    "Colombo",
    "Limeira",
    "Teófilo Otoni",
    "Sinop",
    "Itabuna",
    "Governador Valadares",
    "Marília",
    "Ipatinga",
    "Taboão da Serra",
    "Petrópolis",
    "Vitória da Conquista",
    "Sobral",
    "Indaiatuba",
    "Mossoró",
    "Cachoeiro de Itapemirim",
]

descriptions = [
    {"Galeria": "Culto"},
    {"Festa": "Festeiro"},
    {"Academias": "Fit"},
    {"Parque": "Amante da Natureza"},
    {"Rock": "Rockeiro"},
    {"Headbang": "Rocker"},
    {"Shopping": "Comprador"},
    {"Café": "Amante de café"},
    {"Observatório": "Observador"},
    {"Zoo": "Amante de animais"},
    {"Museu": "Apreciador da arte"},
]


def get_image_url(place_name):
    search_url = "https://www.bing.com/images/search"
    params = {"q": place_name, "FORM": "HDRSC2"}
    response = requests.get(search_url, params=params)
    soup = BeautifulSoup(response.text, "html.parser")

    img_tag = soup.find("a", class_="iusc")
    if img_tag:
        img_url = img_tag.get("m")
        img_url = img_url.split('"murl":"')[1].split('"')[0]
        return img_url
    return None


ratings = [round(random.uniform(3.0, 5.0), 1) for _ in range(100)]
likes = [random.randint(50, 1000) for _ in range(100)]

for i in tqdm(range(1, 101)):
    name = random.choice(names)
    place = {
        "place_id": str(i),
        "name": name,
        "location": random.choice(locations),
        "rating": str(ratings[i - 1]),
        "likes": str(likes[i - 1]),
        "image": get_image_url(name)
        or "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTw_HeSzHfBorKS4muw4IIeVvvRgnhyO8Gn8w&s",
    }
    places_data["places"].append(place)

json_data = json.dumps(places_data, indent=2, ensure_ascii=False)
with open("model/data/places.json", "w", encoding="utf-8") as file:
    file.write(json_data)
